# HOWTO

## Cooking Equipment

```bash
# remove an old virtualenv
make venvclean

# TOFU can also be used without a virtualenv if you have matplotlib and numpy installed on your system

# setup the base virtualenv
make venv

# if you plan to use the c++ version you also have to build the tofu engine
make engine
```

## Ingredients
In order to use TOFU it is required to have a settings file, an exemplary one is shown below.
Paths specified in the settings are always relative to the settings file location.

| Key | Type | Description |
| - | - | - |
| vcdGlob | string | a regular expression like glob to find vcd files |
| pickleGlob | string | another glob to find pickle files which are output by the parse step |
| signalsFileNameLiterals | string | another config file to specify the signals of interest |
| signalsFileName | string | this file is generated by the extractsignalids script and should not be edited |
| signalPropertiesFile | string | this file is generated by the parse step and is required by extractsignalids |
| leakageModel | string | here you can specify either HammningWeight or HammingDistance |
| window | boolean | whether to use a window or not |
| windowFrom | integer | if you only need samples from a specific window you can specify them here as numbers |
| windowTo | integer | if you only need samples from a specific window you can specify them here as numbers |
| valueExtractFunction | string | the default value is the trace index i.e. the nth vcd file it is also possible to specify other functions cf. value.py |
| writeTraces | boolean | specify if the traces should be written or not |
| writeTracesBatchSize | integer | specify the batch write size for traces |
| traceFileName | string | traces file name with a h5 extension |
| align | boolean | if the timestamps are not aligned use true |
| downsample | integer | downsample factor for non aligned vcd timestamps |
| format | string | trace format either `tueisec` or `lascar` |
| *optional entries* |  |  |
| tueisecDocumentationFiles | dictionary | files stored in the `__documentation__` entry of the [TUEISEC Attack-Framework](https://gitlab.lrz.de/TUEISEC-Intern/Attack-Framework) HDF5 format - [c.f. details](#tueisecdocumentationfiles) |
| tueisecAdditionalDataSets | dictionary | files stored as datasets in `0000` group of the [TUEISEC Attack-Framework](https://gitlab.lrz.de/TUEISEC-Intern/Attack-Framework) HDF5 format - [c.f. details](#tueisecadditionaldatasets) |

## Recipe

```bash

# start the tofu root folder or adapt the paths i.e. python3 $(TOFU_PATH)/parse.py

# create a new tofu project folder e.g.
mkdir traces-foo

# acquire your vcd files
# ghdl vivado verilator something like that
# for a ghdl example see the aes folder
# copy them into your tofu project folder
cp /somewhere/*vcd traces-foo/

# start with the settings template
cp example/settings_example.json traces-foo/
# adapt your settings file i.e. the globs

# translate vcd files into pickle files i.e. convert text files to binary files
python3 parse.py --settings traces-foo/settings_example.json

# if you plan only to use a subset of the signals adapt your signalsFileNameLiterals
cp example/signals_name.json traces-foo/
# to find out which signals are inside your simulation use either gtkwave or
# inside an interactive ipython session
# %run signals.py --settings traces-foo/settings_example.json
# print(signals)

# extract signal ids based on the include exclude pattern of signalsFileNameLiterals
python3 extractsignalids.py --settings traces-foo/settings_example.json

# synthesize the traces
python3 synthesize.py --settings traces-foo/settings_example.json

# have fun with your traces

```

## How to extract Values from VCD traces

If you need to extract only the index stick to `valueExtractIndex`, no additional file needed.
Otherwise, implement your value extract function inside the `value.py` file located in the same directory as your settings file and configure your settings accordingly.


``` python

def valueExtractExample(self):
    # numeric ids can be found with the help of signals.py
    value_signal_numeric_id = 123
    # the timestamp of the extraction
    value_signal_time_from = 0

    # iterate over all update and find the required update of a signal at a specific time
    for update in self.updates:
        if update[0] == value_signal_time_from and update[1] == value_signal_numeric_id:
            # extract your value here
            value = None
            break

    return value

```

## Details Regarding TUEISEC Usage
Using the data format from the [TUEISEC Attack-Framework](https://gitlab.lrz.de/TUEISEC-Intern/Attack-Framework), allows for storing additional data with the simulated power traces.
### `tueisecDocumentationFiles`
Similiarly to normal side-channel measurements storing files for documentation purposes can be beneficial.
For example, the source file of the implementation or a block diagram could be added in order to understand the datasets a later point in time.
When using the `tueisec` format, these files can be specified in the following way 
```json
{
  "format": "tueisec",
  "tueisecDocumentationFiles": {
    "blockdiagram.png": "blockdiagram.png",
    "Source code": "./src/top.vhd"
  }
}
```
where the dictionary key (e.g. `Source code`) defines the HDF5 dataset name that is created in the `__documentation__` group of the HDF5 and the dictionary value (e.g. `./src/top.vhd`) defines the path to the respective file.
All relative paths are assumed relative to the settings file, absolute paths can also be provided.

**Note:** The `settings.json` file is always stored in the documentation, even if no explicit files are given - it is not necessary to pass it explicitly.
### `tueisecAdditionalDataSets`
Sometimes, the data processed by the target from which the simulations are generated are of interest, e.g. when conducting DPA, CPA oder template attacks.
When using the `tueisec` format, additional data sets in the HDF5 can be specified in the following way 
```json
{
  "format": "tueisec",
  "tueisecAdditionalDataSets": {
    "ptxt": "./data/plaintext.npy",
    "ctxt": "./data/ciphertext.npy",
    "k": "./data/key.npy"
  }
}
```
where the dictionary key (e.g. `ptxt`) defines the HDF5 dataset name that is created in the `0000` group of the HDF5 and the dictionary value (e.g. `./data/plaintext.npy`) defines the path to the respective file.
In the example above, the datasets `0000/ptxt`, `0000/ctxt` and `0000/k` would be generated.
All relative paths are assumed relative to the settings file, absolute paths can also be provided.
The files are assumed to be numpy datasets, where the first dimension is the number of traces `n_traces` and the second dimension depends on the type of data.
For example for AES, the plaintext array could be of size `n_traces x 16`, i.e. 16 bytes of plaintext. 

**Note:** If the `tueisecAdditionalDataSets` entry does not exist, all `*.npy` files that reside in the folder defined by `pickleGlob` are added as additional datasets.
The file name is used as the dataset name in this case, e.g. a file `plaintext.npy` would result in a dataset `0000/plaintext` in the HDF5.